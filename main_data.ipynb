{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file layout\n",
    "layout = pd.read_excel(\"../Data/mortgage_data/file_layout.xlsx\", sheet_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column name extraction from Freddie Mac documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet_names = layout.keys()\n",
    "# Extract column names and data types for both origination and performance datasets\n",
    "orig_layout = layout['Origination Data File']\n",
    "perf_layout = layout['Monthly Performance Data File']\n",
    "\n",
    "# Extract column names and data types\n",
    "orig_column_names = orig_layout['ATTRIBUTE NAME'].tolist()\n",
    "orig_data_types = orig_layout['DATA TYPE & FORMAT'].tolist()\n",
    "perf_column_names = perf_layout['ATTRIBUTE NAME'].tolist()\n",
    "perf_data_types = perf_layout['DATA TYPE & FORMAT'].tolist()\n",
    "\n",
    "cols_keep_perf = perf_layout['KEEP'].tolist()\n",
    "cols_keep_orig = orig_layout['KEEP'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols_and_NAN(data):\n",
    "    #first drop all columns that only have NaN values\n",
    "    data = data.dropna(axis=1, how='all')\n",
    "    #drop cols_to_drop\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that drops columns where cols_keep is 0\n",
    "def drop_cols(data, cols_keep, col_names):\n",
    "    cols_to_drop = []\n",
    "    for i in range(len(cols_keep)):\n",
    "        if cols_keep[i] == 0:\n",
    "            cols_to_drop.append(col_names[i])\n",
    "    data = data.drop(cols_to_drop, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yearly_data(year, base_dir=\"../Data/mortgage_data\"):\n",
    "    \"\"\"\n",
    "    Load and format the origination and performance datasets for a given year, considering the folder structure.\n",
    "    \n",
    "    Parameters:\n",
    "    - year: The year for which to load the data.\n",
    "    - base_dir: The base directory where the datasets are stored.\n",
    "    \n",
    "    Returns:\n",
    "    - orig_data: Formatted origination dataset for the given year.\n",
    "    - perf_data: Formatted performance dataset for the given year.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Construct file paths considering the \"sample_YYYY\" folder structure\n",
    "    orig_file_path = f\"{base_dir}/sample_{year}/sample_orig_{year}.txt\"\n",
    "    perf_file_path = f\"{base_dir}/sample_{year}/sample_svcg_{year}.txt\"\n",
    "    \n",
    "    # Load origination data\n",
    "    orig_data = pd.read_csv(orig_file_path, sep=\"|\", header=None, low_memory=False)\n",
    "    #select only the first 22 columns\n",
    "    orig_data = orig_data.iloc[:, 0:22]\n",
    "    #rename columns according to orig_column_names first 22\n",
    "    orig_data.columns = orig_column_names[0:22]\n",
    "    \n",
    "    # Load performance data\n",
    "    perf_data = pd.read_csv(perf_file_path, sep=\"|\", header=None, names=perf_column_names, low_memory=False)\n",
    "    \n",
    "    try:\n",
    "        orig_data = drop_cols(orig_data, cols_keep_orig[0:22], orig_column_names)\n",
    "        perf_data = drop_cols(perf_data, cols_keep_perf, perf_column_names)\n",
    "        # display('cols dropped')\n",
    "    except:\n",
    "        # display('no cols dropped')\n",
    "        pass\n",
    "    orig_data = drop_cols_and_NAN(orig_data)\n",
    "    perf_data = drop_cols_and_NAN(perf_data)\n",
    "    return orig_data, perf_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all data at once into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2003"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2006"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2007"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2009"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2010"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2011"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2012"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2013"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2014"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2015"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2016"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2018"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2019"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2020"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2021"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2022"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['orig_1999', 'perf_1999', 'orig_2000', 'perf_2000', 'orig_2001', 'perf_2001', 'orig_2002', 'perf_2002', 'orig_2003', 'perf_2003', 'orig_2004', 'perf_2004', 'orig_2005', 'perf_2005', 'orig_2006', 'perf_2006', 'orig_2007', 'perf_2007', 'orig_2008', 'perf_2008', 'orig_2009', 'perf_2009', 'orig_2010', 'perf_2010', 'orig_2011', 'perf_2011', 'orig_2012', 'perf_2012', 'orig_2013', 'perf_2013', 'orig_2014', 'perf_2014', 'orig_2015', 'perf_2015', 'orig_2016', 'perf_2016', 'orig_2017', 'perf_2017', 'orig_2018', 'perf_2018', 'orig_2019', 'perf_2019', 'orig_2020', 'perf_2020', 'orig_2021', 'perf_2021', 'orig_2022', 'perf_2022'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_all_datasets(start_year=1999, end_year=2022, base_dir=\"../Data/mortgage_data/\"):\n",
    "    \"\"\"\n",
    "    Load all origination and performance datasets for a given range of years.\n",
    "    \n",
    "    Parameters:\n",
    "    - start_year: The starting year (inclusive) for which to load the data.\n",
    "    - end_year: The ending year (inclusive) for which to load the data.\n",
    "    - base_dir: The base directory where the datasets are stored.\n",
    "    \n",
    "    Returns:\n",
    "    - datasets: Dictionary containing formatted origination and performance datasets for the given range of years.\n",
    "    \"\"\"\n",
    "    \n",
    "    datasets = {}\n",
    "    \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        display(year)\n",
    "        orig_data, perf_data = load_yearly_data(year, base_dir=base_dir)\n",
    "        datasets[f\"orig_{year}\"] = orig_data\n",
    "        # display(orig_data.shape)\n",
    "        datasets[f\"perf_{year}\"] = perf_data\n",
    "        # display(perf_data.shape)\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# For demonstration purposes, we'll load only the 2022 sample data\n",
    "# To load all years' data, you would simply call load_all_datasets() without the year range\n",
    "datasets_tot = load_all_datasets(start_year=1999, end_year=2022)\n",
    "datasets_tot.keys()  # Display the keys of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_orig_with_perf(orig_data, perf_data):\n",
    "    merged_data = pd.merge(perf_data, orig_data, on=\"LSN\", how=\"left\")\n",
    "    #move Loan Sequence Number to the front\n",
    "    merged_data = merged_data[[\"LSN\"] + [col for col in merged_data.columns if col != \"LSN\"]]\n",
    "    #move MRP to the front\n",
    "    merged_data = merged_data[[\"MRP\"] + [col for col in merged_data.columns if col != \"MRP\"]]\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged 1999\n",
      "merged 2000\n",
      "merged 2001\n",
      "merged 2002\n",
      "merged 2003\n",
      "merged 2004\n",
      "merged 2005\n",
      "merged 2006\n",
      "merged 2007\n",
      "merged 2008\n",
      "merged 2009\n",
      "merged 2010\n",
      "merged 2011\n",
      "merged 2012\n",
      "merged 2013\n",
      "merged 2014\n",
      "merged 2015\n",
      "merged 2016\n",
      "merged 2017\n",
      "merged 2018\n",
      "merged 2019\n",
      "merged 2020\n",
      "merged 2021\n",
      "merged 2022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fm_1999', 'fm_2000', 'fm_2001', 'fm_2002', 'fm_2003', 'fm_2004', 'fm_2005', 'fm_2006', 'fm_2007', 'fm_2008', 'fm_2009', 'fm_2010', 'fm_2011', 'fm_2012', 'fm_2013', 'fm_2014', 'fm_2015', 'fm_2016', 'fm_2017', 'fm_2018', 'fm_2019', 'fm_2020', 'fm_2021', 'fm_2022'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_all_datasets(datasets):\n",
    "    \"\"\"\n",
    "    Merge all origination and performance datasets within the provided dictionary according to their year.\n",
    "    \n",
    "    Parameters:\n",
    "    - datasets: Dictionary containing formatted origination and performance datasets.\n",
    "    \n",
    "    Returns:\n",
    "    - merged_datasets: Dictionary containing merged datasets for each year.\n",
    "    \"\"\"\n",
    "    merged_datasets = {}\n",
    "    # Extract the range of years from the dataset keys\n",
    "    years = sorted(set(int(key.split(\"_\")[-1]) for key in datasets.keys()))\n",
    "    for year in years:\n",
    "        orig_key = f\"orig_{year}\"\n",
    "        perf_key = f\"perf_{year}\"\n",
    "        if orig_key in datasets and perf_key in datasets:\n",
    "            merged_data = merge_orig_with_perf(datasets[orig_key], datasets[perf_key])\n",
    "            merged_data['Date'] = merged_data['MRP'].astype(str)\n",
    "            merged_datasets[f\"fm_{year}\"] = merged_data\n",
    "            print(\"merged\", year)\n",
    "    return merged_datasets\n",
    "\n",
    "# Merge all datasets in the provided dictionary (in this case, datasets_demo)\n",
    "merged_datasets = merge_all_datasets(datasets_tot)\n",
    "merged_datasets.keys()  # Display the keys of the merged datasets dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2502944, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRP</th>\n",
       "      <th>LSN</th>\n",
       "      <th>CLDS</th>\n",
       "      <th>CIR</th>\n",
       "      <th>ELTV</th>\n",
       "      <th>DDD</th>\n",
       "      <th>CS</th>\n",
       "      <th>FPD</th>\n",
       "      <th>FIRST_F</th>\n",
       "      <th>MD</th>\n",
       "      <th>CLTV</th>\n",
       "      <th>DTI</th>\n",
       "      <th>LTV</th>\n",
       "      <th>OIR</th>\n",
       "      <th>P_TYPE</th>\n",
       "      <th>POSTAL</th>\n",
       "      <th>OLT</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200209</td>\n",
       "      <td>F99Q10000029</td>\n",
       "      <td>0</td>\n",
       "      <td>6.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>618</td>\n",
       "      <td>200210</td>\n",
       "      <td>N</td>\n",
       "      <td>202902</td>\n",
       "      <td>85</td>\n",
       "      <td>24</td>\n",
       "      <td>85</td>\n",
       "      <td>6.375</td>\n",
       "      <td>SF</td>\n",
       "      <td>44200</td>\n",
       "      <td>317</td>\n",
       "      <td>200209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200210</td>\n",
       "      <td>F99Q10000029</td>\n",
       "      <td>0</td>\n",
       "      <td>6.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>618</td>\n",
       "      <td>200210</td>\n",
       "      <td>N</td>\n",
       "      <td>202902</td>\n",
       "      <td>85</td>\n",
       "      <td>24</td>\n",
       "      <td>85</td>\n",
       "      <td>6.375</td>\n",
       "      <td>SF</td>\n",
       "      <td>44200</td>\n",
       "      <td>317</td>\n",
       "      <td>200210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200211</td>\n",
       "      <td>F99Q10000029</td>\n",
       "      <td>0</td>\n",
       "      <td>6.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>618</td>\n",
       "      <td>200210</td>\n",
       "      <td>N</td>\n",
       "      <td>202902</td>\n",
       "      <td>85</td>\n",
       "      <td>24</td>\n",
       "      <td>85</td>\n",
       "      <td>6.375</td>\n",
       "      <td>SF</td>\n",
       "      <td>44200</td>\n",
       "      <td>317</td>\n",
       "      <td>200211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200212</td>\n",
       "      <td>F99Q10000029</td>\n",
       "      <td>0</td>\n",
       "      <td>6.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>618</td>\n",
       "      <td>200210</td>\n",
       "      <td>N</td>\n",
       "      <td>202902</td>\n",
       "      <td>85</td>\n",
       "      <td>24</td>\n",
       "      <td>85</td>\n",
       "      <td>6.375</td>\n",
       "      <td>SF</td>\n",
       "      <td>44200</td>\n",
       "      <td>317</td>\n",
       "      <td>200212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200301</td>\n",
       "      <td>F99Q10000029</td>\n",
       "      <td>0</td>\n",
       "      <td>6.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>618</td>\n",
       "      <td>200210</td>\n",
       "      <td>N</td>\n",
       "      <td>202902</td>\n",
       "      <td>85</td>\n",
       "      <td>24</td>\n",
       "      <td>85</td>\n",
       "      <td>6.375</td>\n",
       "      <td>SF</td>\n",
       "      <td>44200</td>\n",
       "      <td>317</td>\n",
       "      <td>200301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502939</th>\n",
       "      <td>201408</td>\n",
       "      <td>F99Q40245148</td>\n",
       "      <td>0</td>\n",
       "      <td>7.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>674</td>\n",
       "      <td>200612</td>\n",
       "      <td>N</td>\n",
       "      <td>201412</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>7.050</td>\n",
       "      <td>SF</td>\n",
       "      <td>72100</td>\n",
       "      <td>97</td>\n",
       "      <td>201408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502940</th>\n",
       "      <td>201409</td>\n",
       "      <td>F99Q40245148</td>\n",
       "      <td>0</td>\n",
       "      <td>7.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>674</td>\n",
       "      <td>200612</td>\n",
       "      <td>N</td>\n",
       "      <td>201412</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>7.050</td>\n",
       "      <td>SF</td>\n",
       "      <td>72100</td>\n",
       "      <td>97</td>\n",
       "      <td>201409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502941</th>\n",
       "      <td>201410</td>\n",
       "      <td>F99Q40245148</td>\n",
       "      <td>0</td>\n",
       "      <td>7.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>674</td>\n",
       "      <td>200612</td>\n",
       "      <td>N</td>\n",
       "      <td>201412</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>7.050</td>\n",
       "      <td>SF</td>\n",
       "      <td>72100</td>\n",
       "      <td>97</td>\n",
       "      <td>201410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502942</th>\n",
       "      <td>201411</td>\n",
       "      <td>F99Q40245148</td>\n",
       "      <td>0</td>\n",
       "      <td>7.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>674</td>\n",
       "      <td>200612</td>\n",
       "      <td>N</td>\n",
       "      <td>201412</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>7.050</td>\n",
       "      <td>SF</td>\n",
       "      <td>72100</td>\n",
       "      <td>97</td>\n",
       "      <td>201411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502943</th>\n",
       "      <td>201412</td>\n",
       "      <td>F99Q40245148</td>\n",
       "      <td>0</td>\n",
       "      <td>7.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>674</td>\n",
       "      <td>200612</td>\n",
       "      <td>N</td>\n",
       "      <td>201412</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>7.050</td>\n",
       "      <td>SF</td>\n",
       "      <td>72100</td>\n",
       "      <td>97</td>\n",
       "      <td>201412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2502944 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            MRP           LSN CLDS    CIR  ELTV  DDD   CS     FPD FIRST_F   \n",
       "0        200209  F99Q10000029    0  6.375   NaN  NaN  618  200210       N  \\\n",
       "1        200210  F99Q10000029    0  6.375   NaN  NaN  618  200210       N   \n",
       "2        200211  F99Q10000029    0  6.375   NaN  NaN  618  200210       N   \n",
       "3        200212  F99Q10000029    0  6.375   NaN  NaN  618  200210       N   \n",
       "4        200301  F99Q10000029    0  6.375   NaN  NaN  618  200210       N   \n",
       "...         ...           ...  ...    ...   ...  ...  ...     ...     ...   \n",
       "2502939  201408  F99Q40245148    0  7.050   NaN  NaN  674  200612       N   \n",
       "2502940  201409  F99Q40245148    0  7.050   NaN  NaN  674  200612       N   \n",
       "2502941  201410  F99Q40245148    0  7.050   NaN  NaN  674  200612       N   \n",
       "2502942  201411  F99Q40245148    0  7.050   NaN  NaN  674  200612       N   \n",
       "2502943  201412  F99Q40245148    0  7.050   NaN  NaN  674  200612       N   \n",
       "\n",
       "             MD  CLTV  DTI  LTV    OIR P_TYPE  POSTAL  OLT    Date  \n",
       "0        202902    85   24   85  6.375     SF   44200  317  200209  \n",
       "1        202902    85   24   85  6.375     SF   44200  317  200210  \n",
       "2        202902    85   24   85  6.375     SF   44200  317  200211  \n",
       "3        202902    85   24   85  6.375     SF   44200  317  200212  \n",
       "4        202902    85   24   85  6.375     SF   44200  317  200301  \n",
       "...         ...   ...  ...  ...    ...    ...     ...  ...     ...  \n",
       "2502939  201412    80   50   59  7.050     SF   72100   97  201408  \n",
       "2502940  201412    80   50   59  7.050     SF   72100   97  201409  \n",
       "2502941  201412    80   50   59  7.050     SF   72100   97  201410  \n",
       "2502942  201412    80   50   59  7.050     SF   72100   97  201411  \n",
       "2502943  201412    80   50   59  7.050     SF   72100   97  201412  \n",
       "\n",
       "[2502944 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fm_1999 = merged_datasets['fm_1999']\n",
    "display(fm_1999.shape)\n",
    "display(fm_1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del datasets_tot\n",
    "del cols_keep_orig\n",
    "del cols_keep_perf\n",
    "del layout\n",
    "del orig_column_names\n",
    "del orig_data_types\n",
    "del perf_column_names\n",
    "del perf_data_types\n",
    "del perf_layout\n",
    "del orig_layout\n",
    "del fm_1999\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Columns and add 3ZiP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1         NaN\n",
       "2         NaN\n",
       "3         NaN\n",
       "4         NaN\n",
       "           ..\n",
       "2502939   NaN\n",
       "2502940   NaN\n",
       "2502941   NaN\n",
       "2502942   NaN\n",
       "2502943   NaN\n",
       "Name: ELTV, Length: 2502944, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fm_1999 added and dropped\n",
      "fm_2000 added and dropped\n",
      "fm_2001 added and dropped\n",
      "fm_2002 added and dropped\n",
      "fm_2003 added and dropped\n",
      "fm_2004 added and dropped\n",
      "fm_2005 added and dropped\n",
      "fm_2006 added and dropped\n",
      "fm_2007 added and dropped\n",
      "fm_2008 added and dropped\n",
      "fm_2009 added and dropped\n",
      "fm_2010 added and dropped\n",
      "fm_2011 added and dropped\n",
      "fm_2012 added and dropped\n",
      "fm_2013 added and dropped\n",
      "fm_2014 added and dropped\n",
      "fm_2015 added and dropped\n",
      "fm_2016 added and dropped\n",
      "fm_2017 added and dropped\n",
      "fm_2018 added and dropped\n",
      "fm_2019 added and dropped\n",
      "fm_2020 added and dropped\n",
      "fm_2021 added and dropped\n",
      "fm_2022 added and dropped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>3ZIP</th>\n",
       "      <th>LSN</th>\n",
       "      <th>CLDS</th>\n",
       "      <th>CIR</th>\n",
       "      <th>ELTV</th>\n",
       "      <th>DDD</th>\n",
       "      <th>CS</th>\n",
       "      <th>FPD</th>\n",
       "      <th>FIRST_F</th>\n",
       "      <th>MD</th>\n",
       "      <th>CLTV</th>\n",
       "      <th>DTI</th>\n",
       "      <th>LTV</th>\n",
       "      <th>OIR</th>\n",
       "      <th>P_TYPE</th>\n",
       "      <th>OLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202202</td>\n",
       "      <td>125</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>2.625</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>False</td>\n",
       "      <td>203702</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202203</td>\n",
       "      <td>125</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>2.625</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>False</td>\n",
       "      <td>203702</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202204</td>\n",
       "      <td>125</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>2.625</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>False</td>\n",
       "      <td>203702</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202205</td>\n",
       "      <td>125</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>2.625</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>False</td>\n",
       "      <td>203702</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202206</td>\n",
       "      <td>125</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>2.625</td>\n",
       "      <td>39</td>\n",
       "      <td>False</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>False</td>\n",
       "      <td>203702</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date  3ZIP           LSN  CLDS    CIR  ELTV    DDD   CS     FPD  FIRST_F   \n",
       "0  202202   125  F22Q10000012     0  2.625    57  False  768  202203    False  \\\n",
       "1  202203   125  F22Q10000012     0  2.625    48  False  768  202203    False   \n",
       "2  202204   125  F22Q10000012     0  2.625    52  False  768  202203    False   \n",
       "3  202205   125  F22Q10000012     0  2.625    40  False  768  202203    False   \n",
       "4  202206   125  F22Q10000012     0  2.625    39  False  768  202203    False   \n",
       "\n",
       "       MD  CLTV  DTI  LTV    OIR P_TYPE  OLT  \n",
       "0  203702    57   28   57  2.625     SF  180  \n",
       "1  203702    57   28   57  2.625     SF  180  \n",
       "2  203702    57   28   57  2.625     SF  180  \n",
       "3  203702    57   28   57  2.625     SF  180  \n",
       "4  203702    57   28   57  2.625     SF  180  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in merged_datasets.keys():\n",
    "    merged_datasets[key]['3ZIP'] = merged_datasets[key]['POSTAL'].astype(str).str[:3].astype('int16')\n",
    "    #Transform DDD to 0 if NaN and 1 if Y\n",
    "    merged_datasets[key]['DDD'] = merged_datasets[key]['DDD'].fillna(0)\n",
    "    merged_datasets[key]['DDD'] = merged_datasets[key]['DDD'].replace('Y', 1)\n",
    "    #Transform FIRST_F to 0 if N and 1 if Y\n",
    "    merged_datasets[key]['FIRST_F'] = merged_datasets[key]['FIRST_F'].replace('N', 0)\n",
    "    merged_datasets[key]['FIRST_F'] = merged_datasets[key]['FIRST_F'].replace('Y', 1)\n",
    "    #Convert int64 to int32 or int16 or bool\n",
    "    merged_datasets[key]['DDD'] = merged_datasets[key]['DDD'].astype('bool')\n",
    "    merged_datasets[key]['FIRST_F'] = merged_datasets[key]['FIRST_F'].astype('bool')\n",
    "    merged_datasets[key]['ELTV'] = merged_datasets[key]['ELTV'].astype('Int16')\n",
    "    merged_datasets[key]['CS'] = merged_datasets[key]['CS'].astype('Int16')\n",
    "    merged_datasets[key]['CLTV'] = merged_datasets[key]['CLTV'].astype('Int16')\n",
    "    merged_datasets[key]['OLT'] = merged_datasets[key]['OLT'].astype('Int16')\n",
    "    merged_datasets[key]['DTI'] = merged_datasets[key]['DTI'].astype('Int16')\n",
    "    merged_datasets[key]['FPD'] = merged_datasets[key]['FPD'].astype('Int32')\n",
    "    merged_datasets[key]['MD'] = merged_datasets[key]['MD'].astype('int32')\n",
    "    #Drop POSTAL and MRP\n",
    "    merged_datasets[key].drop(['POSTAL'], axis=1, inplace=True)\n",
    "    merged_datasets[key].drop(['MRP'], axis=1, inplace=True)\n",
    "    #Move Date and 3ZIP to the front\n",
    "    merged_datasets[key] = merged_datasets[key][[\"Date\", \"3ZIP\"] + [col for col in merged_datasets[key].columns if col not in [\"Date\", \"3ZIP\"]]]\n",
    "    print(f\"{key} added and dropped\")\n",
    "merged_datasets['fm_2022'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date        object\n",
       "3ZIP         int32\n",
       "LSN         object\n",
       "CLDS         int64\n",
       "CIR        float64\n",
       "ELTV         Int16\n",
       "DDD           bool\n",
       "CS           Int16\n",
       "FPD          Int32\n",
       "FIRST_F       bool\n",
       "MD           int32\n",
       "CLTV         Int16\n",
       "DTI          Int16\n",
       "LTV          int64\n",
       "OIR        float64\n",
       "P_TYPE      object\n",
       "OLT          Int16\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count     419440.0\n",
       "mean     36.752868\n",
       "std      15.328947\n",
       "min            1.0\n",
       "25%           30.0\n",
       "50%           38.0\n",
       "75%           44.0\n",
       "max          999.0\n",
       "Name: DTI, dtype: Float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(merged_datasets['fm_2022'].dtypes)\n",
    "display(merged_datasets['fm_2022']['DTI'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/mortgage_data/fm_datasets.pickle\", \"wb\") as f:\n",
    "    pickle.dump(merged_datasets, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here you can work with fm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"../Data/mortgage_data/fm_datasets.pickle\", \"rb\") as f:\n",
    "    fm_datasets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to merge macro data to performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_macro_data(perf_data, macro_data, perf_date_col, macro_date_col):\n",
    "    \"\"\"\n",
    "    Merge macroeconomic data with the performance dataset based on the date.\n",
    "    \n",
    "    Parameters:\n",
    "    - perf_data: The performance dataset.\n",
    "    - macro_data: The macroeconomic dataset.\n",
    "    - perf_date_col: The date column name in the performance dataset.\n",
    "    - macro_date_col: The date column name in the macroeconomic dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - Merged dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Merge datasets based on the date\n",
    "    merged_data = pd.merge(perf_data, macro_data, left_on=perf_date_col, right_on=macro_date_col, how='left')\n",
    "    return merged_data\n",
    "\n",
    "# Sample usage of the functions can be provided if datasets are available.\n",
    "# For now, these functions are generic and can be adapted to actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(value):\n",
    "    value = str(value)\n",
    "    if len(value) == 4:\n",
    "        return value\n",
    "    else:\n",
    "        try:\n",
    "            # Handle dates like \"2022-01-15\"\n",
    "            return datetime.strptime(value, \"%Y-%m-%d\").year\n",
    "        except:\n",
    "            try:\n",
    "                # Handle dates like \"202201\"\n",
    "                return datetime.strptime(value, \"%Y%m\").year\n",
    "            except:\n",
    "                return value\n",
    "\n",
    "def extract_month(value):\n",
    "    value = str(value)\n",
    "    try:\n",
    "        # Handle month names like \"Dec\", \"Jan\", etc.\n",
    "        return datetime.strptime(value, \"%b\").month\n",
    "    except:\n",
    "        try:\n",
    "            # Handle dates like \"2022-01-15\"\n",
    "            return datetime.strptime(value, \"%Y-%m-%d\").month\n",
    "        except:\n",
    "            try:\n",
    "                # Handle dates like \"202201\" or \"20221\"\n",
    "                return datetime.strptime(value, \"%Y%m\").month\n",
    "            except:\n",
    "                return value  #or some default value\n",
    "#function that takes month column and year column and returns a \"YYYYmm\" string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "# Create a database connection\n",
    "db_path = \"../Database/thesis_database.db\"\n",
    "conn = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing fm_1999 to database...\n",
      "Writing fm_2000 to database...\n",
      "Writing fm_2001 to database...\n",
      "Writing fm_2002 to database...\n",
      "Writing fm_2003 to database...\n",
      "Writing fm_2004 to database...\n",
      "Writing fm_2005 to database...\n",
      "Writing fm_2006 to database...\n",
      "Writing fm_2007 to database...\n",
      "Writing fm_2008 to database...\n",
      "Writing fm_2009 to database...\n",
      "Writing fm_2010 to database...\n",
      "Writing fm_2011 to database...\n",
      "Writing fm_2012 to database...\n",
      "Writing fm_2013 to database...\n",
      "Writing fm_2014 to database...\n",
      "Writing fm_2015 to database...\n",
      "Writing fm_2016 to database...\n",
      "Writing fm_2017 to database...\n",
      "Writing fm_2018 to database...\n",
      "Writing fm_2019 to database...\n",
      "Writing fm_2020 to database...\n",
      "Writing fm_2021 to database...\n",
      "Writing fm_2022 to database...\n"
     ]
    }
   ],
   "source": [
    "for key, dataset in fm_datasets.items():\n",
    "    print(\"Writing\", key, \"to database...\")\n",
    "    dataset.to_sql(key, conn, if_exists = \"replace\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del fm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>3ZIP</th>\n",
       "      <th>LSN</th>\n",
       "      <th>CLDS</th>\n",
       "      <th>CIR</th>\n",
       "      <th>ELTV</th>\n",
       "      <th>DDD</th>\n",
       "      <th>CS</th>\n",
       "      <th>FPD</th>\n",
       "      <th>FIRST_F</th>\n",
       "      <th>MD</th>\n",
       "      <th>CLTV</th>\n",
       "      <th>DTI</th>\n",
       "      <th>LTV</th>\n",
       "      <th>OIR</th>\n",
       "      <th>P_TYPE</th>\n",
       "      <th>OLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202202</td>\n",
       "      <td>125</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>2.625</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>0</td>\n",
       "      <td>203702</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202203</td>\n",
       "      <td>125</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>2.625</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>0</td>\n",
       "      <td>203702</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202204</td>\n",
       "      <td>125</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>2.625</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>0</td>\n",
       "      <td>203702</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202205</td>\n",
       "      <td>125</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>2.625</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>0</td>\n",
       "      <td>203702</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202206</td>\n",
       "      <td>125</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>2.625</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>0</td>\n",
       "      <td>203702</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date  3ZIP           LSN  CLDS    CIR  ELTV  DDD   CS     FPD  FIRST_F   \n",
       "0  202202   125  F22Q10000012     0  2.625    57    0  768  202203        0  \\\n",
       "1  202203   125  F22Q10000012     0  2.625    48    0  768  202203        0   \n",
       "2  202204   125  F22Q10000012     0  2.625    52    0  768  202203        0   \n",
       "3  202205   125  F22Q10000012     0  2.625    40    0  768  202203        0   \n",
       "4  202206   125  F22Q10000012     0  2.625    39    0  768  202203        0   \n",
       "\n",
       "       MD  CLTV  DTI  LTV    OIR P_TYPE  OLT  \n",
       "0  203702    57   28   57  2.625     SF  180  \n",
       "1  203702    57   28   57  2.625     SF  180  \n",
       "2  203702    57   28   57  2.625     SF  180  \n",
       "3  203702    57   28   57  2.625     SF  180  \n",
       "4  203702    57   28   57  2.625     SF  180  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query that binds fm_2022 and fm_2021\n",
    "query = \"SELECT * FROM fm_2022 UNION ALL SELECT * FROM fm_2021;\"\n",
    "\n",
    "fm_21_22 = pd.read_sql_query(query, conn)\n",
    "#save to csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge ENSO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>MEI</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>12</td>\n",
       "      <td>0.47</td>\n",
       "      <td>197912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>0.27</td>\n",
       "      <td>197901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>197902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979</td>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>197903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979</td>\n",
       "      <td>4</td>\n",
       "      <td>0.35</td>\n",
       "      <td>197904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month   MEI    Date\n",
       "0  1979     12  0.47  197912\n",
       "1  1979      1  0.27  197901\n",
       "2  1979      2 -0.04  197902\n",
       "3  1979      3  0.26  197903\n",
       "4  1979      4  0.35  197904"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load enso_mei_long.csv\n",
    "enso_mei_long = pd.read_csv(\"../Data/enso_mei_long.csv\")\n",
    "#Transform Month Dec to 12, Jan to 1, Feb to 2, etc.\n",
    "enso_mei_long['Month'] = enso_mei_long['Month'].apply(extract_month)\n",
    "enso_mei_long['Date'] = enso_mei_long.apply(lambda row: f\"{row['Year'].astype(int)}{row['Month'].astype(int):02}\", axis = 1)\n",
    "enso_mei_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enso_mei_long = enso_mei_long[['Date', 'MEI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enso_mei_long.to_sql('enso_mei_long', conn, if_exists = \"replace\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add HURR data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "hrcn_data = pd.read_csv('mainland_usa_gdf_HRCN.csv', dtype={'3ZIP':str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrcn_data.head()\n",
    "hrcn_data_short = hrcn_data[['3ZIP', 'HRCN_RISKS', 'HRCN_RISKV', 'HRCN_EVNTS', 'HRCN_EALS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3ZIP</th>\n",
       "      <th>HRCN_RISKS</th>\n",
       "      <th>HRCN_RISKV</th>\n",
       "      <th>HRCN_EVNTS</th>\n",
       "      <th>HRCN_EALS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360</td>\n",
       "      <td>67.653656</td>\n",
       "      <td>1.014608e+06</td>\n",
       "      <td>13.0</td>\n",
       "      <td>66.364029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365</td>\n",
       "      <td>98.878421</td>\n",
       "      <td>1.895320e+08</td>\n",
       "      <td>50.0</td>\n",
       "      <td>99.005620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360</td>\n",
       "      <td>77.164648</td>\n",
       "      <td>3.079796e+06</td>\n",
       "      <td>21.0</td>\n",
       "      <td>72.805880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>350</td>\n",
       "      <td>51.099148</td>\n",
       "      <td>2.226110e+05</td>\n",
       "      <td>11.0</td>\n",
       "      <td>49.070471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>350</td>\n",
       "      <td>54.015253</td>\n",
       "      <td>3.010121e+05</td>\n",
       "      <td>6.0</td>\n",
       "      <td>52.399481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>531</td>\n",
       "      <td>17.900404</td>\n",
       "      <td>2.029927e+04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.584955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>530</td>\n",
       "      <td>14.042171</td>\n",
       "      <td>1.429553e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.769131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>531</td>\n",
       "      <td>24.001795</td>\n",
       "      <td>3.034120e+04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.096412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>549</td>\n",
       "      <td>5.966801</td>\n",
       "      <td>5.715024e+03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.879810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>549</td>\n",
       "      <td>21.085689</td>\n",
       "      <td>2.454064e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.303070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2224 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     3ZIP  HRCN_RISKS    HRCN_RISKV  HRCN_EVNTS  HRCN_EALS\n",
       "0     360   67.653656  1.014608e+06        13.0  66.364029\n",
       "1     365   98.878421  1.895320e+08        50.0  99.005620\n",
       "2     360   77.164648  3.079796e+06        21.0  72.805880\n",
       "3     350   51.099148  2.226110e+05        11.0  49.070471\n",
       "4     350   54.015253  3.010121e+05         6.0  52.399481\n",
       "...   ...         ...           ...         ...        ...\n",
       "2219  531   17.900404  2.029927e+04         1.0  19.584955\n",
       "2220  530   14.042171  1.429553e+04         0.0  17.769131\n",
       "2221  531   24.001795  3.034120e+04         1.0  29.096412\n",
       "2222  549    5.966801  5.715024e+03         1.0   5.879810\n",
       "2223  549   21.085689  2.454064e+04         0.0  23.303070\n",
       "\n",
       "[2224 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrcn_data_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2224"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrcn_data_short.to_sql('hrcn_data_short', conn, if_exists = \"replace\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/yannickpichardo/Desktop/Thesis_repo/master_thesis/main_data.ipynb Cell 40\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yannickpichardo/Desktop/Thesis_repo/master_thesis/main_data.ipynb#Y122sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m conn\u001b[39m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conn' is not defined"
     ]
    }
   ],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to merge zip data to performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_zip_data(perf_data, zip_data, perf_zip_col, zip_data_col):\n",
    "    \"\"\"\n",
    "    Merge external data with the performance dataset based on the 3zip code.\n",
    "    \n",
    "    Parameters:\n",
    "    - perf_data: The performance dataset.\n",
    "    - zip_data: The external dataset with 3zip level information.\n",
    "    - perf_zip_col: The zip column name in the performance dataset (might be 5-digit zip).\n",
    "    - zip_data_col: The 3zip column name in the external dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - Merged dataset.\n",
    "    \"\"\"\n",
    "    # Convert 5-digit zip code to 3zip format\n",
    "    perf_data['3zip'] = perf_data[perf_zip_col].astype(str).str[:3]\n",
    "    zip_data['3zip'] = zip_data[zip_data_col].astype(str).str[:3]\n",
    "    \n",
    "    # Merge datasets based on the 3zip code\n",
    "    merged_data = pd.merge(perf_data, zip_data, left_on='3zip', right_on='3zip', how='left')\n",
    "    \n",
    "    return merged_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
