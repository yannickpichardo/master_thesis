{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file layout\n",
    "layout = pd.read_excel(\"../Data/mortgage_data/file_layout.xlsx\", sheet_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column name extraction from Freddie Mac documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet_names = layout.keys()\n",
    "# Extract column names and data types for both origination and performance datasets\n",
    "orig_layout = layout['Origination Data File']\n",
    "perf_layout = layout['Monthly Performance Data File']\n",
    "\n",
    "# Extract column names and data types\n",
    "orig_column_names = orig_layout['ATTRIBUTE NAME'].tolist()\n",
    "orig_data_types = orig_layout['DATA TYPE & FORMAT'].tolist()\n",
    "perf_column_names = perf_layout['ATTRIBUTE NAME'].tolist()\n",
    "perf_data_types = perf_layout['DATA TYPE & FORMAT'].tolist()\n",
    "\n",
    "cols_keep_perf = perf_layout['KEEP'].tolist()\n",
    "cols_keep_orig = orig_layout['KEEP'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_keep_orig[0:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols_and_NAN(data):\n",
    "    #first drop all columns that only have NaN values\n",
    "    data = data.dropna(axis=1, how='all')\n",
    "    #drop cols_to_drop\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that drops columns where cols_keep is 0\n",
    "def drop_cols(data, cols_keep, col_names):\n",
    "    cols_to_drop = []\n",
    "    for i in range(len(cols_keep)):\n",
    "        if cols_keep[i] == 0:\n",
    "            cols_to_drop.append(col_names[i])\n",
    "    data = data.drop(cols_to_drop, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yearly_data(year, base_dir=\"../Data/mortgage_data\"):\n",
    "    \"\"\"\n",
    "    Load and format the origination and performance datasets for a given year, considering the folder structure.\n",
    "    \n",
    "    Parameters:\n",
    "    - year: The year for which to load the data.\n",
    "    - base_dir: The base directory where the datasets are stored.\n",
    "    \n",
    "    Returns:\n",
    "    - orig_data: Formatted origination dataset for the given year.\n",
    "    - perf_data: Formatted performance dataset for the given year.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Construct file paths considering the \"sample_YYYY\" folder structure\n",
    "    orig_file_path = f\"{base_dir}/sample_{year}/sample_orig_{year}.txt\"\n",
    "    perf_file_path = f\"{base_dir}/sample_{year}/sample_svcg_{year}.txt\"\n",
    "    \n",
    "    # Load origination data\n",
    "    orig_data = pd.read_csv(orig_file_path, sep=\"|\", header=None, low_memory=False)\n",
    "    #select only the first 22 columns\n",
    "    orig_data = orig_data.iloc[:, 0:22]\n",
    "    #rename columns according to orig_column_names first 22\n",
    "    orig_data.columns = orig_column_names[0:22]\n",
    "    \n",
    "    # Load performance data\n",
    "    perf_data = pd.read_csv(perf_file_path, sep=\"|\", header=None, names=perf_column_names, low_memory=False)\n",
    "    \n",
    "    try:\n",
    "        orig_data = drop_cols(orig_data, cols_keep_orig[0:22], orig_column_names)\n",
    "        perf_data = drop_cols(perf_data, cols_keep_perf, perf_column_names)\n",
    "        # display('cols dropped')\n",
    "    except:\n",
    "        # display('no cols dropped')\n",
    "        pass\n",
    "    orig_data = drop_cols_and_NAN(orig_data)\n",
    "    perf_data = drop_cols_and_NAN(perf_data)\n",
    "    return orig_data, perf_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all data at once into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2003"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2006"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2007"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2009"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2010"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2011"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2012"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2013"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2014"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2015"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2016"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2018"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2019"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2020"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2021"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2022"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['orig_1999', 'perf_1999', 'orig_2000', 'perf_2000', 'orig_2001', 'perf_2001', 'orig_2002', 'perf_2002', 'orig_2003', 'perf_2003', 'orig_2004', 'perf_2004', 'orig_2005', 'perf_2005', 'orig_2006', 'perf_2006', 'orig_2007', 'perf_2007', 'orig_2008', 'perf_2008', 'orig_2009', 'perf_2009', 'orig_2010', 'perf_2010', 'orig_2011', 'perf_2011', 'orig_2012', 'perf_2012', 'orig_2013', 'perf_2013', 'orig_2014', 'perf_2014', 'orig_2015', 'perf_2015', 'orig_2016', 'perf_2016', 'orig_2017', 'perf_2017', 'orig_2018', 'perf_2018', 'orig_2019', 'perf_2019', 'orig_2020', 'perf_2020', 'orig_2021', 'perf_2021', 'orig_2022', 'perf_2022'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_all_datasets(start_year=1999, end_year=2022, base_dir=\"../Data/mortgage_data/\"):\n",
    "    \"\"\"\n",
    "    Load all origination and performance datasets for a given range of years.\n",
    "    \n",
    "    Parameters:\n",
    "    - start_year: The starting year (inclusive) for which to load the data.\n",
    "    - end_year: The ending year (inclusive) for which to load the data.\n",
    "    - base_dir: The base directory where the datasets are stored.\n",
    "    \n",
    "    Returns:\n",
    "    - datasets: Dictionary containing formatted origination and performance datasets for the given range of years.\n",
    "    \"\"\"\n",
    "    \n",
    "    datasets = {}\n",
    "    \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        display(year)\n",
    "        orig_data, perf_data = load_yearly_data(year, base_dir=base_dir)\n",
    "        datasets[f\"orig_{year}\"] = orig_data\n",
    "        # display(orig_data.shape)\n",
    "        datasets[f\"perf_{year}\"] = perf_data\n",
    "        # display(perf_data.shape)\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# For demonstration purposes, we'll load only the 2022 sample data\n",
    "# To load all years' data, you would simply call load_all_datasets() without the year range\n",
    "datasets_demo = load_all_datasets(start_year=1999, end_year=2022)\n",
    "datasets_demo.keys()  # Display the keys of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../Data/mortgage_data/datasets_demo.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(datasets_demo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"../Data/mortgage_data/datasets_demo.pickle\", \"rb\") as f:\n",
    "#    datasets_unmerged = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_orig_with_perf(orig_data, perf_data):\n",
    "    merged_data = pd.merge(perf_data, orig_data, on=\"LSN\", how=\"left\")\n",
    "    #move Loan Sequence Number to the front\n",
    "    merged_data = merged_data[[\"LSN\"] + [col for col in merged_data.columns if col != \"LSN\"]]\n",
    "    #move MRP to the front\n",
    "    merged_data = merged_data[[\"MRP\"] + [col for col in merged_data.columns if col != \"MRP\"]]\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged 1999\n",
      "merged 2000\n",
      "merged 2001\n",
      "merged 2002\n",
      "merged 2003\n",
      "merged 2004\n",
      "merged 2005\n",
      "merged 2006\n",
      "merged 2007\n",
      "merged 2008\n",
      "merged 2009\n",
      "merged 2010\n",
      "merged 2011\n",
      "merged 2012\n",
      "merged 2013\n",
      "merged 2014\n",
      "merged 2015\n",
      "merged 2016\n",
      "merged 2017\n",
      "merged 2018\n",
      "merged 2019\n",
      "merged 2020\n",
      "merged 2021\n",
      "merged 2022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fm_1999', 'fm_2000', 'fm_2001', 'fm_2002', 'fm_2003', 'fm_2004', 'fm_2005', 'fm_2006', 'fm_2007', 'fm_2008', 'fm_2009', 'fm_2010', 'fm_2011', 'fm_2012', 'fm_2013', 'fm_2014', 'fm_2015', 'fm_2016', 'fm_2017', 'fm_2018', 'fm_2019', 'fm_2020', 'fm_2021', 'fm_2022'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_all_datasets(datasets):\n",
    "    \"\"\"\n",
    "    Merge all origination and performance datasets within the provided dictionary according to their year.\n",
    "    \n",
    "    Parameters:\n",
    "    - datasets: Dictionary containing formatted origination and performance datasets.\n",
    "    \n",
    "    Returns:\n",
    "    - merged_datasets: Dictionary containing merged datasets for each year.\n",
    "    \"\"\"\n",
    "    merged_datasets = {}\n",
    "    # Extract the range of years from the dataset keys\n",
    "    years = sorted(set(int(key.split(\"_\")[-1]) for key in datasets.keys()))\n",
    "    for year in years:\n",
    "        orig_key = f\"orig_{year}\"\n",
    "        perf_key = f\"perf_{year}\"\n",
    "        if orig_key in datasets and perf_key in datasets:\n",
    "            merged_data = merge_orig_with_perf(datasets[orig_key], datasets[perf_key])\n",
    "            merged_data['Date'] = merged_data['MRP'].astype(str)\n",
    "            merged_datasets[f\"fm_{year}\"] = merged_data\n",
    "            print(\"merged\", year)\n",
    "    return merged_datasets\n",
    "\n",
    "# Merge all datasets in the provided dictionary (in this case, datasets_demo)\n",
    "merged_datasets_demo = merge_all_datasets(datasets_demo)\n",
    "merged_datasets_demo.keys()  # Display the keys of the merged datasets dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419440, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRP</th>\n",
       "      <th>LSN</th>\n",
       "      <th>CLDS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MONTS_REM</th>\n",
       "      <th>CIR</th>\n",
       "      <th>ELTV</th>\n",
       "      <th>DDD</th>\n",
       "      <th>CS</th>\n",
       "      <th>FPD</th>\n",
       "      <th>FIRST_F</th>\n",
       "      <th>MD</th>\n",
       "      <th>CLTV</th>\n",
       "      <th>DTI</th>\n",
       "      <th>LTV</th>\n",
       "      <th>OIR</th>\n",
       "      <th>P_TYPE</th>\n",
       "      <th>POSTAL</th>\n",
       "      <th>OLT</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202202</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>2.625</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>N</td>\n",
       "      <td>203702</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>12500</td>\n",
       "      <td>180</td>\n",
       "      <td>202202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202203</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>2.625</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>N</td>\n",
       "      <td>203702</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>12500</td>\n",
       "      <td>180</td>\n",
       "      <td>202203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202204</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "      <td>2.625</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>N</td>\n",
       "      <td>203702</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>12500</td>\n",
       "      <td>180</td>\n",
       "      <td>202204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202205</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>2.625</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>N</td>\n",
       "      <td>203702</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>12500</td>\n",
       "      <td>180</td>\n",
       "      <td>202205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202206</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>176</td>\n",
       "      <td>2.625</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>N</td>\n",
       "      <td>203702</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>12500</td>\n",
       "      <td>180</td>\n",
       "      <td>202206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MRP           LSN  CLDS  AGE  MONTS_REM    CIR  ELTV  DDD   CS     FPD   \n",
       "0  202202  F22Q10000012     0    0        180  2.625    57  NaN  768  202203  \\\n",
       "1  202203  F22Q10000012     0    1        179  2.625    48  NaN  768  202203   \n",
       "2  202204  F22Q10000012     0    2        178  2.625    52  NaN  768  202203   \n",
       "3  202205  F22Q10000012     0    3        177  2.625    40  NaN  768  202203   \n",
       "4  202206  F22Q10000012     0    4        176  2.625    39  NaN  768  202203   \n",
       "\n",
       "  FIRST_F      MD  CLTV  DTI  LTV    OIR P_TYPE  POSTAL  OLT    Date  \n",
       "0       N  203702    57   28   57  2.625     SF   12500  180  202202  \n",
       "1       N  203702    57   28   57  2.625     SF   12500  180  202203  \n",
       "2       N  203702    57   28   57  2.625     SF   12500  180  202204  \n",
       "3       N  203702    57   28   57  2.625     SF   12500  180  202205  \n",
       "4       N  203702    57   28   57  2.625     SF   12500  180  202206  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fm_2022 = merged_datasets_demo['fm_2022']\n",
    "display(fm_2022.shape)\n",
    "display(fm_2022.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del datasets_demo\n",
    "del cols_keep_orig\n",
    "del cols_keep_perf\n",
    "del layout\n",
    "del orig_column_names\n",
    "del orig_data_types\n",
    "del perf_column_names\n",
    "del perf_data_types\n",
    "del perf_layout\n",
    "del orig_layout\n",
    "del fm_2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../Data/mortgage_data/fm_datasets.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(merged_datasets_demo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/mortgage_data/fm_datasets.pickle\", \"rb\") as f:\n",
    "    fm_datasets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to merge macro data to performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_macro_data(perf_data, macro_data, perf_date_col, macro_date_col):\n",
    "    \"\"\"\n",
    "    Merge macroeconomic data with the performance dataset based on the date.\n",
    "    \n",
    "    Parameters:\n",
    "    - perf_data: The performance dataset.\n",
    "    - macro_data: The macroeconomic dataset.\n",
    "    - perf_date_col: The date column name in the performance dataset.\n",
    "    - macro_date_col: The date column name in the macroeconomic dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - Merged dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Merge datasets based on the date\n",
    "    merged_data = pd.merge(perf_data, macro_data, left_on=perf_date_col, right_on=macro_date_col, how='left')\n",
    "    return merged_data\n",
    "\n",
    "# Sample usage of the functions can be provided if datasets are available.\n",
    "# For now, these functions are generic and can be adapted to actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(value):\n",
    "    value = str(value)\n",
    "    if len(value) == 4:\n",
    "        return value\n",
    "    else:\n",
    "        try:\n",
    "            # Handle dates like \"2022-01-15\"\n",
    "            return datetime.strptime(value, \"%Y-%m-%d\").year\n",
    "        except:\n",
    "            try:\n",
    "                # Handle dates like \"202201\"\n",
    "                return datetime.strptime(value, \"%Y%m\").year\n",
    "            except:\n",
    "                return value\n",
    "\n",
    "def extract_month(value):\n",
    "    value = str(value)\n",
    "    try:\n",
    "        # Handle month names like \"Dec\", \"Jan\", etc.\n",
    "        return datetime.strptime(value, \"%b\").month\n",
    "    except:\n",
    "        try:\n",
    "            # Handle dates like \"2022-01-15\"\n",
    "            return datetime.strptime(value, \"%Y-%m-%d\").month\n",
    "        except:\n",
    "            try:\n",
    "                # Handle dates like \"202201\" or \"20221\"\n",
    "                return datetime.strptime(value, \"%Y%m\").month\n",
    "            except:\n",
    "                return value  #or some default value\n",
    "#function that takes month column and year column and returns a \"YYYYmm\" string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge ENSO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>MEI</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>12</td>\n",
       "      <td>0.47</td>\n",
       "      <td>197912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>0.27</td>\n",
       "      <td>197901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>197902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979</td>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>197903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979</td>\n",
       "      <td>4</td>\n",
       "      <td>0.35</td>\n",
       "      <td>197904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month   MEI    Date\n",
       "0  1979     12  0.47  197912\n",
       "1  1979      1  0.27  197901\n",
       "2  1979      2 -0.04  197902\n",
       "3  1979      3  0.26  197903\n",
       "4  1979      4  0.35  197904"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load enso_mei_long.csv\n",
    "enso_mei_long = pd.read_csv(\"../Data/enso_mei_long.csv\")\n",
    "#Transform Month Dec to 12, Jan to 1, Feb to 2, etc.\n",
    "enso_mei_long['Month'] = enso_mei_long['Month'].apply(extract_month)\n",
    "enso_mei_long['Date'] = enso_mei_long.apply(lambda row: f\"{row['Year'].astype(int)}{row['Month'].astype(int):02}\", axis = 1)\n",
    "enso_mei_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged fm_1999\n",
      "merged fm_2000\n",
      "merged fm_2001\n",
      "merged fm_2002\n",
      "merged fm_2003\n",
      "merged fm_2004\n",
      "merged fm_2005\n",
      "merged fm_2006\n",
      "merged fm_2007\n",
      "merged fm_2008\n",
      "merged fm_2009\n",
      "merged fm_2010\n",
      "merged fm_2011\n",
      "merged fm_2012\n",
      "merged fm_2013\n",
      "merged fm_2014\n",
      "merged fm_2015\n",
      "merged fm_2016\n",
      "merged fm_2017\n",
      "merged fm_2018\n",
      "merged fm_2019\n",
      "merged fm_2020\n",
      "merged fm_2021\n",
      "merged fm_2022\n"
     ]
    }
   ],
   "source": [
    "#merge enso_mei_long with all fm_YYYY datasets by Date in for loop\n",
    "for key in fm_datasets.keys():\n",
    "    fm_datasets[key] = merge_macro_data(fm_datasets[key], enso_mei_long, 'Date', 'Date')\n",
    "    print(\"merged\", key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a database connection\n",
    "db_path = \"../Database/thesis_database.db\"\n",
    "conn = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing fm_1999 to database...\n",
      "Writing fm_2000 to database...\n",
      "Writing fm_2001 to database...\n",
      "Writing fm_2002 to database...\n",
      "Writing fm_2003 to database...\n",
      "Writing fm_2004 to database...\n",
      "Writing fm_2005 to database...\n",
      "Writing fm_2006 to database...\n",
      "Writing fm_2007 to database...\n",
      "Writing fm_2008 to database...\n",
      "Writing fm_2009 to database...\n",
      "Writing fm_2010 to database...\n",
      "Writing fm_2011 to database...\n",
      "Writing fm_2012 to database...\n",
      "Writing fm_2013 to database...\n",
      "Writing fm_2014 to database...\n",
      "Writing fm_2015 to database...\n",
      "Writing fm_2016 to database...\n",
      "Writing fm_2017 to database...\n",
      "Writing fm_2018 to database...\n",
      "Writing fm_2019 to database...\n",
      "Writing fm_2020 to database...\n",
      "Writing fm_2021 to database...\n",
      "Writing fm_2022 to database...\n"
     ]
    }
   ],
   "source": [
    "for key, dataset in fm_datasets.items():\n",
    "    print(\"Writing\", key, \"to database...\")\n",
    "    dataset.to_sql(key, conn, if_exists = \"replace\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del fm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"../Database/thesis_database.db\"\n",
    "conn = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRP</th>\n",
       "      <th>LSN</th>\n",
       "      <th>CLDS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MONTS_REM</th>\n",
       "      <th>CIR</th>\n",
       "      <th>ELTV</th>\n",
       "      <th>DDD</th>\n",
       "      <th>CS</th>\n",
       "      <th>FPD</th>\n",
       "      <th>...</th>\n",
       "      <th>DTI</th>\n",
       "      <th>LTV</th>\n",
       "      <th>OIR</th>\n",
       "      <th>P_TYPE</th>\n",
       "      <th>POSTAL</th>\n",
       "      <th>OLT</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>MEI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202202</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>2.625</td>\n",
       "      <td>57</td>\n",
       "      <td>None</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>12500</td>\n",
       "      <td>180</td>\n",
       "      <td>202202</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202203</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>2.625</td>\n",
       "      <td>48</td>\n",
       "      <td>None</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>12500</td>\n",
       "      <td>180</td>\n",
       "      <td>202203</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202204</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "      <td>2.625</td>\n",
       "      <td>52</td>\n",
       "      <td>None</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>12500</td>\n",
       "      <td>180</td>\n",
       "      <td>202204</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202205</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>2.625</td>\n",
       "      <td>40</td>\n",
       "      <td>None</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>12500</td>\n",
       "      <td>180</td>\n",
       "      <td>202205</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202206</td>\n",
       "      <td>F22Q10000012</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>176</td>\n",
       "      <td>2.625</td>\n",
       "      <td>39</td>\n",
       "      <td>None</td>\n",
       "      <td>768</td>\n",
       "      <td>202203</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>2.625</td>\n",
       "      <td>SF</td>\n",
       "      <td>12500</td>\n",
       "      <td>180</td>\n",
       "      <td>202206</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>-2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398348</th>\n",
       "      <td>202303</td>\n",
       "      <td>F21Q40865007</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>354</td>\n",
       "      <td>3.000</td>\n",
       "      <td>63</td>\n",
       "      <td>None</td>\n",
       "      <td>795</td>\n",
       "      <td>202210</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>65</td>\n",
       "      <td>3.000</td>\n",
       "      <td>PU</td>\n",
       "      <td>26500</td>\n",
       "      <td>360</td>\n",
       "      <td>202303</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398349</th>\n",
       "      <td>202212</td>\n",
       "      <td>F21Q40865038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>3.375</td>\n",
       "      <td>68</td>\n",
       "      <td>None</td>\n",
       "      <td>817</td>\n",
       "      <td>202301</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>3.375</td>\n",
       "      <td>PU</td>\n",
       "      <td>16000</td>\n",
       "      <td>360</td>\n",
       "      <td>202212</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398350</th>\n",
       "      <td>202301</td>\n",
       "      <td>F21Q40865038</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>359</td>\n",
       "      <td>3.375</td>\n",
       "      <td>59</td>\n",
       "      <td>None</td>\n",
       "      <td>817</td>\n",
       "      <td>202301</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>3.375</td>\n",
       "      <td>PU</td>\n",
       "      <td>16000</td>\n",
       "      <td>360</td>\n",
       "      <td>202301</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398351</th>\n",
       "      <td>202302</td>\n",
       "      <td>F21Q40865038</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>358</td>\n",
       "      <td>3.375</td>\n",
       "      <td>59</td>\n",
       "      <td>None</td>\n",
       "      <td>817</td>\n",
       "      <td>202301</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>3.375</td>\n",
       "      <td>PU</td>\n",
       "      <td>16000</td>\n",
       "      <td>360</td>\n",
       "      <td>202302</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398352</th>\n",
       "      <td>202303</td>\n",
       "      <td>F21Q40865038</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>357</td>\n",
       "      <td>3.375</td>\n",
       "      <td>58</td>\n",
       "      <td>None</td>\n",
       "      <td>817</td>\n",
       "      <td>202301</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>3.375</td>\n",
       "      <td>PU</td>\n",
       "      <td>16000</td>\n",
       "      <td>360</td>\n",
       "      <td>202303</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1398353 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            MRP           LSN  CLDS  AGE  MONTS_REM    CIR  ELTV   DDD   CS   \n",
       "0        202202  F22Q10000012     0    0        180  2.625    57  None  768  \\\n",
       "1        202203  F22Q10000012     0    1        179  2.625    48  None  768   \n",
       "2        202204  F22Q10000012     0    2        178  2.625    52  None  768   \n",
       "3        202205  F22Q10000012     0    3        177  2.625    40  None  768   \n",
       "4        202206  F22Q10000012     0    4        176  2.625    39  None  768   \n",
       "...         ...           ...   ...  ...        ...    ...   ...   ...  ...   \n",
       "1398348  202303  F21Q40865007     0    6        354  3.000    63  None  795   \n",
       "1398349  202212  F21Q40865038     0    0        360  3.375    68  None  817   \n",
       "1398350  202301  F21Q40865038     0    1        359  3.375    59  None  817   \n",
       "1398351  202302  F21Q40865038     0    2        358  3.375    59  None  817   \n",
       "1398352  202303  F21Q40865038     0    3        357  3.375    58  None  817   \n",
       "\n",
       "            FPD  ... DTI  LTV    OIR  P_TYPE  POSTAL  OLT    Date  Year   \n",
       "0        202203  ...  28   57  2.625      SF   12500  180  202202  2022  \\\n",
       "1        202203  ...  28   57  2.625      SF   12500  180  202203  2022   \n",
       "2        202203  ...  28   57  2.625      SF   12500  180  202204  2022   \n",
       "3        202203  ...  28   57  2.625      SF   12500  180  202205  2022   \n",
       "4        202203  ...  28   57  2.625      SF   12500  180  202206  2022   \n",
       "...         ...  ...  ..  ...    ...     ...     ...  ...     ...   ...   \n",
       "1398348  202210  ...  19   65  3.000      PU   26500  360  202303  2023   \n",
       "1398349  202301  ...  33   60  3.375      PU   16000  360  202212  2022   \n",
       "1398350  202301  ...  33   60  3.375      PU   16000  360  202301  2023   \n",
       "1398351  202301  ...  33   60  3.375      PU   16000  360  202302  2023   \n",
       "1398352  202301  ...  33   60  3.375      PU   16000  360  202303  2023   \n",
       "\n",
       "         Month   MEI  \n",
       "0            2 -1.28  \n",
       "1            3 -1.76  \n",
       "2            4 -1.88  \n",
       "3            5 -2.07  \n",
       "4            6 -2.10  \n",
       "...        ...   ...  \n",
       "1398348      3 -0.41  \n",
       "1398349     12 -1.06  \n",
       "1398350      1 -0.81  \n",
       "1398351      2 -0.67  \n",
       "1398352      3 -0.41  \n",
       "\n",
       "[1398353 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1398353, 23)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"SELECT * FROM fm_2021\"\n",
    "\n",
    "#query that binds fm_2022 and fm_2021\n",
    "query = \"SELECT * FROM fm_2022 UNION ALL SELECT * FROM fm_2021;\"\n",
    "\n",
    "\n",
    "FM_20212022 = pd.read_sql_query(query, conn)\n",
    "#save to csv\n",
    "# fm_2021.to_csv(\"../Data/mortgage_data/fm_2021.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do panel data regression on FM_20212022 per postal code and Date \n",
    "\n",
    "\n",
    "#Start with Panel Data Regression\n",
    "#First, create a panel data frame\n",
    "#convert Date to datetime\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_20212022['Date'] = pd.to_datetime(FM_20212022['Date'], format='%Y%m')\n",
    "\n",
    "FM_20212022 = FM_20212022.set_index(['POSTAL', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:                   ELTV   R-squared:                        0.2273\n",
      "Estimator:                   PanelOLS   R-squared (Between):              0.6481\n",
      "No. Observations:             1398353   R-squared (Within):               0.0052\n",
      "Date:                Mon, Oct 09 2023   R-squared (Overall):              0.2273\n",
      "Time:                        20:49:02   Log-likelihood                -9.584e+06\n",
      "Cov. Estimator:            Unadjusted                                           \n",
      "                                        F-statistic:                   1.371e+05\n",
      "Entities:                         881   P-value                           0.0000\n",
      "Avg Obs:                       1587.2   Distribution:               F(3,1398350)\n",
      "Min Obs:                       3.0000                                           \n",
      "Max Obs:                    1.503e+04   F-statistic (robust):          1.371e+05\n",
      "                                        P-value                           0.0000\n",
      "Time periods:                      26   Distribution:               F(3,1398350)\n",
      "Avg Obs:                    5.378e+04                                           \n",
      "Min Obs:                       3564.0                                           \n",
      "Max Obs:                    9.561e+04                                           \n",
      "                                                                                \n",
      "                             Parameter Estimates                              \n",
      "==============================================================================\n",
      "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------\n",
      "MEI           -4.1905     0.3745    -11.189     0.0000     -4.9245     -3.4564\n",
      "CS             0.0294     0.0009     32.215     0.0000      0.0276      0.0312\n",
      "MONTS_REM      0.2999     0.0021     141.13     0.0000      0.2957      0.3041\n",
      "==============================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod = PanelOLS(dependent=FM_20212022['y'], exog=FM_20212022[['x1', 'x2']])\n",
    "res = mod.fit()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to merge zip data to performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_zip_data(perf_data, zip_data, perf_zip_col, zip_data_col):\n",
    "    \"\"\"\n",
    "    Merge external data with the performance dataset based on the 3zip code.\n",
    "    \n",
    "    Parameters:\n",
    "    - perf_data: The performance dataset.\n",
    "    - zip_data: The external dataset with 3zip level information.\n",
    "    - perf_zip_col: The zip column name in the performance dataset (might be 5-digit zip).\n",
    "    - zip_data_col: The 3zip column name in the external dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - Merged dataset.\n",
    "    \"\"\"\n",
    "    # Convert 5-digit zip code to 3zip format\n",
    "    perf_data['3zip'] = perf_data[perf_zip_col].astype(str).str[:3]\n",
    "    zip_data['3zip'] = zip_data[zip_data_col].astype(str).str[:3]\n",
    "    \n",
    "    # Merge datasets based on the 3zip code\n",
    "    merged_data = pd.merge(perf_data, zip_data, left_on='3zip', right_on='3zip', how='left')\n",
    "    \n",
    "    return merged_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
