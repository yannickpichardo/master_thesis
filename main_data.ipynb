{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the file layout\n",
    "layout = pd.read_excel(\"../Data/mortgage_data/file_layout.xlsx\", sheet_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column name extraction from Freddie Mac documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet_names = layout.keys()\n",
    "# Extract column names and data types for both origination and performance datasets\n",
    "orig_layout = layout['Origination Data File']\n",
    "perf_layout = layout['Monthly Performance Data File']\n",
    "\n",
    "# Extract column names and data types\n",
    "orig_column_names = orig_layout['ATTRIBUTE NAME'].tolist()\n",
    "orig_data_types = orig_layout['DATA TYPE & FORMAT'].tolist()\n",
    "perf_column_names = perf_layout['ATTRIBUTE NAME'].tolist()\n",
    "perf_data_types = perf_layout['DATA TYPE & FORMAT'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols_and_NAN(data, cols_to_drop):\n",
    "    #first drop all columns that only have NaN values\n",
    "    data = data.dropna(axis=1, how='all')\n",
    "    #drop cols_to_drop\n",
    "    data = data.drop(cols_to_drop, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_no_risk_loans(data, loans_to_drop):\n",
    "    \n",
    "    #drop loans_to_drop\n",
    "    data = data.drop(loans_to_drop, axis=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yearly_data(year, base_dir=\"../Data/mortgage_data\"):\n",
    "    \"\"\"\n",
    "    Load and format the origination and performance datasets for a given year, considering the folder structure.\n",
    "    \n",
    "    Parameters:\n",
    "    - year: The year for which to load the data.\n",
    "    - base_dir: The base directory where the datasets are stored.\n",
    "    \n",
    "    Returns:\n",
    "    - orig_data: Formatted origination dataset for the given year.\n",
    "    - perf_data: Formatted performance dataset for the given year.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Construct file paths considering the \"sample_YYYY\" folder structure\n",
    "    orig_file_path = f\"{base_dir}/sample_{year}/sample_orig_{year}.txt\"\n",
    "    perf_file_path = f\"{base_dir}/sample_{year}/sample_svcg_{year}.txt\"\n",
    "    \n",
    "    # Load origination data\n",
    "    orig_data = pd.read_csv(orig_file_path, sep=\"|\", header=None, names=orig_column_names, low_memory=False)\n",
    "    # Load performance data\n",
    "    perf_data = pd.read_csv(perf_file_path, sep=\"|\", header=None, names=perf_column_names, low_memory=False)\n",
    "    \n",
    "    perf_cols_drop = []#select columns you want to drop\n",
    "    orig_cols_drop = []#select columns you want to drop\n",
    "    orig_data = drop_cols_and_NAN(orig_data, orig_cols_drop)\n",
    "    perf_data = drop_cols_and_NAN(perf_data, perf_cols_drop)\n",
    "\n",
    "    return orig_data, perf_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all data at once into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['orig_1999', 'perf_1999', 'orig_2000', 'perf_2000', 'orig_2001', 'perf_2001', 'orig_2002', 'perf_2002', 'orig_2003', 'perf_2003', 'orig_2004', 'perf_2004', 'orig_2005', 'perf_2005', 'orig_2006', 'perf_2006', 'orig_2007', 'perf_2007', 'orig_2008', 'perf_2008', 'orig_2009', 'perf_2009', 'orig_2010', 'perf_2010', 'orig_2011', 'perf_2011', 'orig_2012', 'perf_2012', 'orig_2013', 'perf_2013', 'orig_2014', 'perf_2014', 'orig_2015', 'perf_2015', 'orig_2016', 'perf_2016', 'orig_2017', 'perf_2017', 'orig_2018', 'perf_2018', 'orig_2019', 'perf_2019', 'orig_2020', 'perf_2020', 'orig_2021', 'perf_2021', 'orig_2022', 'perf_2022'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_all_datasets(start_year=1999, end_year=2022, base_dir=\"../Data/mortgage_data/\"):\n",
    "    \"\"\"\n",
    "    Load all origination and performance datasets for a given range of years.\n",
    "    \n",
    "    Parameters:\n",
    "    - start_year: The starting year (inclusive) for which to load the data.\n",
    "    - end_year: The ending year (inclusive) for which to load the data.\n",
    "    - base_dir: The base directory where the datasets are stored.\n",
    "    \n",
    "    Returns:\n",
    "    - datasets: Dictionary containing formatted origination and performance datasets for the given range of years.\n",
    "    \"\"\"\n",
    "    \n",
    "    datasets = {}\n",
    "    \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        orig_data, perf_data = load_yearly_data(year, base_dir=base_dir)\n",
    "        \n",
    "        datasets[f\"orig_{year}\"] = orig_data\n",
    "        datasets[f\"perf_{year}\"] = perf_data\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# For demonstration purposes, we'll load only the 2022 sample data\n",
    "# To load all years' data, you would simply call load_all_datasets() without the year range\n",
    "datasets_demo = load_all_datasets(start_year=1999, end_year=2022)\n",
    "datasets_demo.keys()  # Display the keys of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_orig_with_perf(orig_data, perf_data):\n",
    "    merged_data = pd.merge(perf_data, orig_data, on=\"Loan Sequence Number\", how=\"left\")\n",
    "    #move Loan Sequence Number to the front\n",
    "    merged_data = merged_data[[\"Loan Sequence Number\"] + [col for col in merged_data.columns if col != \"Loan Sequence Number\"]]\n",
    "    #move Monthly Reporting Period to the front\n",
    "    merged_data = merged_data[[\"Monthly Reporting Period\"] + [col for col in merged_data.columns if col != \"Monthly Reporting Period\"]]\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
      "1999\n",
      "merged 1999\n",
      "2000\n",
      "merged 2000\n",
      "2001\n",
      "merged 2001\n",
      "2002\n",
      "merged 2002\n",
      "2003\n",
      "merged 2003\n",
      "2004\n",
      "merged 2004\n",
      "2005\n",
      "merged 2005\n",
      "2006\n",
      "merged 2006\n",
      "2007\n",
      "merged 2007\n",
      "2008\n",
      "merged 2008\n",
      "2009\n",
      "merged 2009\n",
      "2010\n",
      "merged 2010\n",
      "2011\n",
      "merged 2011\n",
      "2012\n",
      "merged 2012\n",
      "2013\n",
      "merged 2013\n",
      "2014\n",
      "merged 2014\n",
      "2015\n",
      "merged 2015\n",
      "2016\n",
      "merged 2016\n",
      "2017\n",
      "merged 2017\n",
      "2018\n",
      "merged 2018\n",
      "2019\n",
      "merged 2019\n",
      "2020\n",
      "merged 2020\n",
      "2021\n",
      "merged 2021\n",
      "2022\n",
      "merged 2022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['fm_1999', 'fm_2000', 'fm_2001', 'fm_2002', 'fm_2003', 'fm_2004', 'fm_2005', 'fm_2006', 'fm_2007', 'fm_2008', 'fm_2009', 'fm_2010', 'fm_2011', 'fm_2012', 'fm_2013', 'fm_2014', 'fm_2015', 'fm_2016', 'fm_2017', 'fm_2018', 'fm_2019', 'fm_2020', 'fm_2021', 'fm_2022'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_all_datasets(datasets):\n",
    "    \"\"\"\n",
    "    Merge all origination and performance datasets within the provided dictionary according to their year.\n",
    "    \n",
    "    Parameters:\n",
    "    - datasets: Dictionary containing formatted origination and performance datasets.\n",
    "    \n",
    "    Returns:\n",
    "    - merged_datasets: Dictionary containing merged datasets for each year.\n",
    "    \"\"\"\n",
    "    merged_datasets = {}\n",
    "    # Extract the range of years from the dataset keys\n",
    "    years = sorted(set(int(key.split(\"_\")[-1]) for key in datasets.keys()))\n",
    "    for year in years:\n",
    "        orig_key = f\"orig_{year}\"\n",
    "        perf_key = f\"perf_{year}\"\n",
    "        if orig_key in datasets and perf_key in datasets:\n",
    "            merged_data = merge_orig_with_perf(datasets[orig_key], datasets[perf_key])\n",
    "            merged_datasets[f\"fm_{year}\"] = merged_data\n",
    "            print(\"merged\", year)\n",
    "    return merged_datasets\n",
    "\n",
    "# Merge all datasets in the provided dictionary (in this case, datasets_demo)\n",
    "merged_datasets_demo = merge_all_datasets(datasets_demo)\n",
    "merged_datasets_demo.keys()  # Display the keys of the merged datasets dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to merge macro data to performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_macro_data(perf_data, macro_data, perf_date_col, macro_date_col):\n",
    "    \"\"\"\n",
    "    Merge macroeconomic data with the performance dataset based on the date.\n",
    "    \n",
    "    Parameters:\n",
    "    - perf_data: The performance dataset.\n",
    "    - macro_data: The macroeconomic dataset.\n",
    "    - perf_date_col: The date column name in the performance dataset.\n",
    "    - macro_date_col: The date column name in the macroeconomic dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - Merged dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the date columns are in a monthly format\n",
    "    perf_data[perf_date_col] = pd.to_datetime(perf_data[perf_date_col]).dt.to_period('M')\n",
    "    macro_data[macro_date_col] = pd.to_datetime(macro_data[macro_date_col]).dt.to_period('M')\n",
    "    \n",
    "    # Merge datasets based on the date\n",
    "    merged_data = pd.merge(perf_data, macro_data, left_on=perf_date_col, right_on=macro_date_col, how='left')\n",
    "    return merged_data\n",
    "\n",
    "# Sample usage of the functions can be provided if datasets are available.\n",
    "# For now, these functions are generic and can be adapted to actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>MEI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>12</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979</td>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979</td>\n",
       "      <td>4</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month   MEI\n",
       "0  1979     12  0.47\n",
       "1  1979      1  0.27\n",
       "2  1979      2 -0.04\n",
       "3  1979      3  0.26\n",
       "4  1979      4  0.35"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "#Load enso_mei_long.csv\n",
    "enso_mei_long = pd.read_csv(\"../Data/enso_mei_long.csv\")\n",
    "#Transform Month Dec to 12, Jan to 1, Feb to 2, etc.\n",
    "enso_mei_long['Month'] = enso_mei_long['Month'].apply(lambda x: datetime.strptime(x, \"%b\").month)\n",
    "enso_mei_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>MEI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>12</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979</td>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979</td>\n",
       "      <td>4</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month   MEI\n",
       "0  1979     12  0.47\n",
       "1  1979      1  0.27\n",
       "2  1979      2 -0.04\n",
       "3  1979      3  0.26\n",
       "4  1979      4  0.35"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def transform_date_column(df, column_month_name, column_year_name):\n",
    "    \"\"\"\n",
    "    Transform a DataFrame column with various date formats to its month numerical representation.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: The input DataFrame.\n",
    "    - column_name: The name of the column to be transformed.\n",
    "    \n",
    "    Returns:\n",
    "    - df: DataFrame with the transformed column.\n",
    "    \"\"\"\n",
    "    def extract_year(value):\n",
    "        if len(str(value)) == 4:\n",
    "            return value\n",
    "        else:\n",
    "            try:\n",
    "                # Handle dates like \"2022-01-15\"\n",
    "                return datetime.strptime(value, \"%Y-%m-%d\").year\n",
    "            except:\n",
    "                try:\n",
    "                    # Handle dates like \"202201\"\n",
    "                    return datetime.strptime(value, \"%Y%m\").year\n",
    "                except:\n",
    "                    return value\n",
    "\n",
    "    def extract_month(value):\n",
    "        #Check if value is already a YYYY format\n",
    "        \n",
    "        try:\n",
    "            # Handle month names like \"Dec\", \"Jan\", etc.\n",
    "            return datetime.strptime(value, \"%b\").month\n",
    "        except:\n",
    "            try:\n",
    "                # Handle dates like \"2022-01-15\"\n",
    "                return datetime.strptime(value, \"%Y-%m-%d\").month\n",
    "            except:\n",
    "                try:\n",
    "                    # Handle dates like \"202201\"\n",
    "                    return datetime.strptime(value, \"%Y%m\").month\n",
    "                except:\n",
    "                    return value  #or some default value\n",
    "        \n",
    "    df[column_month_name] = df[column_month_name].apply(extract_month)\n",
    "    df[column_year_name] = df[column_year_name].apply(extract_year)\n",
    "    return df\n",
    "#Load enso_mei_long.csv\n",
    "enso_mei_long = pd.read_csv(\"../Data/enso_mei_long.csv\")\n",
    "#Transform Month Dec to 12, Jan to 1, Feb to 2, etc.\n",
    "enso_mei_long = transform_date_column(enso_mei_long, \"Month\", \"Year\")\n",
    "enso_mei_long.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fm_2022' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/yannickpichardo/Desktop/Thesis_repo/master_thesis/main_data.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yannickpichardo/Desktop/Thesis_repo/master_thesis/main_data.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fm_2022\u001b[39m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fm_2022' is not defined"
     ]
    }
   ],
   "source": [
    "fm_2022 = merged_datasets_demo['fm_2022']\n",
    "fm_2022.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge enso_mei_long Year 2022 onto fm_2022 where Month of enso_mei_long = Monthly Reporting Period of fm_2022\n",
    "merged_2022 = merge_macro_data(merged_datasets_demo[\"fm_2022\"], enso_mei_long, \"Monthly Reporting Period\", \"Month\")\n",
    "merged_2022.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to merge zip data to performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_zip_data(perf_data, zip_data, perf_zip_col, zip_data_col):\n",
    "    \"\"\"\n",
    "    Merge external data with the performance dataset based on the 3zip code.\n",
    "    \n",
    "    Parameters:\n",
    "    - perf_data: The performance dataset.\n",
    "    - zip_data: The external dataset with 3zip level information.\n",
    "    - perf_zip_col: The zip column name in the performance dataset (might be 5-digit zip).\n",
    "    - zip_data_col: The 3zip column name in the external dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - Merged dataset.\n",
    "    \"\"\"\n",
    "    # Convert 5-digit zip code to 3zip format\n",
    "    perf_data['3zip'] = perf_data[perf_zip_col].astype(str).str[:3]\n",
    "    zip_data['3zip'] = zip_data[zip_data_col].astype(str).str[:3]\n",
    "    \n",
    "    # Merge datasets based on the 3zip code\n",
    "    merged_data = pd.merge(perf_data, zip_data, left_on='3zip', right_on='3zip', how='left')\n",
    "    \n",
    "    return merged_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
